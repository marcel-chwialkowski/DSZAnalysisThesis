{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical propagation on a toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In this notebook we present how our empirical propagation approach works on a toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../src/DSI.jl\")\n",
    "include(\"../src/Zono_utils.jl\")\n",
    "include(\"../src/PZono.jl\")\n",
    "include(\"../src/DSZ.jl\")\n",
    "include(\"../src/propagation.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the weights and biases for our toy network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toy network allowing us for Lipschitz approximation \n",
    "W1 = [1.0 -1.0; 1.0 1.0; -1.0 2.0]\n",
    "b1 = [0.0; 0.0; 0.0]\n",
    "W2 = [1.0 -1.0 1.0; 1.0 -1.0 2.0]\n",
    "b2 = [0.0; 0.0]\n",
    "\n",
    "L1 = Layer(W1, b1, ReLU())\n",
    "L2 = Layer(W2, b2, Id())\n",
    "full_net = Network([L1;L2])\n",
    "\n",
    "x = [normal(interval(0,1),1), normal(interval(0,1),1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_discretization_steps = 100\n",
    "ProbabilityBoundsAnalysis.setSteps(nb_discretization_steps)\n",
    "pz = pbox_approximate_nnet(full_net,x,true) \n",
    "if print_figures\n",
    "    ProbabilityBoundsAnalysis.plot(pz[1])\n",
    "    PyPlot.savefig(\"../pictures/Toy2Output1.png\")\n",
    "    ProbabilityBoundsAnalysis.plot(pz[2])\n",
    "    PyPlot.savefig(\"../pictures/Toy2Output2.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Lipschitz verifier, we obtain that this network has a Lipschitz constant of 5 in the L2 norm. Recall that the Lipschitz constant in L1 norm will be at most $5\\sqrt{2} = 7.071$. We combinatorically generate a $\\varepsilon$-covering of the input, assuming the independence of inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the input p-boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_desc = [([0,1],1),([0,1],1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psamples = gaussian_samples(x_desc, 1000, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generated a covering with $\\varepsilon = 0.005$ and $1000$ samples for each input within the covering. The psamples vector contains all of the samples. The first dimension of the vector represents the number of inputs of the neural network (for each input, we have a covering). The second dimension represents the cdfs within one pbox, and the third the number of samples for each cdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(size(psamples))\n",
    "println(size(psamples[1]))\n",
    "println(size(psamples[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propagate samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outps = propagate_gaussians_multhread(psamples, full_net, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=1000\n",
    "for i in 1:length(outps[1][1])\n",
    "    ProbabilityBoundsAnalysis.plot(pz[i])\n",
    "    for j in 1:length(outps)\n",
    "        data = [outps[j][k][i] for k in 1:num_samples]\n",
    "        cdf = empirical_cdf(data)\n",
    "        plot(cdf[1], cdf[2], marker=\"o\", linestyle=\"-\")\n",
    "    end\n",
    "    filename = string(\"../pictures/empirical_cdfs_propagation_\",\"full_net\",\"_\", i, \".png\")\n",
    "    PyPlot.savefig(filename)    \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (16 threads) 1.11.2",
   "language": "julia",
   "name": "julia-_16-threads_-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
